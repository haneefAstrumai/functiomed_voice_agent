import { useState, useEffect, useRef, useCallback } from 'react'
import { Room, RoomEvent } from 'livekit-client'

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Constants
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const BACKEND_URL = 'http://localhost:8000'

// Maps agent state names â†’ stepper step index
const STATE_TO_STEP = {
  collect_service:  0,
  collect_date:     1,
  collect_slot:     2,
  show_slots:       2,
  collect_name:     3,
  collect_email:    4,
  collect_phone:    5,
  confirm_booking:  6,
  booking_done:     7,
}

const STEPS = [
  { label: 'Service', icon: 'ğŸ’Š' },
  { label: 'Date',    icon: 'ğŸ“…' },
  { label: 'Time',    icon: 'ğŸ•' },
  { label: 'Name',    icon: 'ğŸ‘¤' },
  { label: 'Email',   icon: 'ğŸ“§' },
  { label: 'Phone',   icon: 'ğŸ“' },
  { label: 'Confirm', icon: 'âœ…' },
  { label: 'Done',    icon: 'ğŸ‰' },
]

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Helper: check Web Speech API availability
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const isSpeechRecognitionSupported = () =>
  'SpeechRecognition' in window || 'webkitSpeechRecognition' in window

const SpeechRecognitionAPI =
  window.SpeechRecognition || window.webkitSpeechRecognition


// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Main Component
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export default function VoiceAgent() {

  // â”€â”€ Connection state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const [connectionStatus, setConnectionStatus] = useState('offline')
  // 'offline' | 'connecting' | 'online'

  // â”€â”€ Voice state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const [listening, setListening]           = useState(false)
  const [isAgentSpeaking, setIsAgentSpeaking] = useState(false)
  const [transcript, setTranscript]         = useState('')

  // â”€â”€ Conversation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const [messages, setMessages]   = useState([])
  const [agentState, setAgentState] = useState('idle')
  const [language, setLanguage]   = useState('en')
  // language used for STT lang attr and TTS lang attr

  // â”€â”€ Error â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const [error, setError] = useState('')

  // â”€â”€ Refs (survive re-renders, no re-render on change) â”€â”€â”€â”€â”€â”€
  const roomRef            = useRef(null)
  const recognitionRef     = useRef(null)
  const synthRef           = useRef(window.speechSynthesis)
  const messagesEndRef     = useRef(null)
  const isAgentSpeakingRef = useRef(false)   // used inside callbacks

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Auto-scroll chat to bottom whenever messages change
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }, [messages])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Cleanup on unmount
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  useEffect(() => {
    return () => {
      synthRef.current.cancel()
      recognitionRef.current?.abort()
      roomRef.current?.disconnect()
    }
  }, [])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Add a message to the chat log
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const addMessage = useCallback((role, text) => {
    setMessages(prev => [...prev, { role, text, id: Date.now() + Math.random() }])
  }, [])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Detect language from agent response text
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const detectLanguage = useCallback((text) => {
    const germanWords = ['ich','bitte','danke','mÃ¶chte','termin',
                         'ja','nein','willkommen','kÃ¶nnen','datum']
    const lower = text.toLowerCase()
    const score = germanWords.filter(w => lower.includes(w)).length
    return score >= 2 ? 'de' : 'en'
  }, [])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // TTS â€” speak agent response text
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const speak = useCallback((text) => {
    if (!text) return

    // Cancel any ongoing speech first
    synthRef.current.cancel()

    const utterance  = new SpeechSynthesisUtterance(text)
    const detectedLang = detectLanguage(text)
    setLanguage(detectedLang)
    utterance.lang  = detectedLang === 'de' ? 'de-DE' : 'en-US'
    utterance.rate  = 0.93
    utterance.pitch = 1.0

    // Try to pick a good voice
    const voices = synthRef.current.getVoices()
    const preferredVoice = voices.find(v =>
      v.lang.startsWith(detectedLang === 'de' ? 'de' : 'en') && v.localService
    ) || voices.find(v =>
      v.lang.startsWith(detectedLang === 'de' ? 'de' : 'en')
    )
    if (preferredVoice) utterance.voice = preferredVoice

    utterance.onstart = () => {
      setIsAgentSpeaking(true)
      isAgentSpeakingRef.current = true
      setListening(false)
      setTranscript('')
    }

    utterance.onend = () => {
      setIsAgentSpeaking(false)
      isAgentSpeakingRef.current = false
      // Auto-start listening after agent finishes speaking
      // Small delay so user hears agent fully
      setTimeout(() => {
        if (roomRef.current) startListening()
      }, 400)
    }

    utterance.onerror = (e) => {
      console.warn('TTS error:', e)
      setIsAgentSpeaking(false)
      isAgentSpeakingRef.current = false
    }

    synthRef.current.speak(utterance)
  }, [detectLanguage])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Send text to agent via LiveKit DataChannel
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const sendToAgent = useCallback(async (text) => {
    if (!roomRef.current || !text.trim()) return

    addMessage('user', text)
    setTranscript('')

    const payload = JSON.stringify({ type: 'user_message', text })
    await roomRef.current.localParticipant.publishData(
      new TextEncoder().encode(payload),
      { reliable: true }
    )
    console.log('â†’ Sent to agent:', text)
  }, [addMessage])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // STT â€” start listening with Web Speech API
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const startListening = useCallback(() => {
    // Don't start if agent is speaking or already listening
    if (isAgentSpeakingRef.current) return
    if (!isSpeechRecognitionSupported()) return
    if (!roomRef.current) return

    // Abort any existing recognition session
    if (recognitionRef.current) {
      try { recognitionRef.current.abort() } catch (_) {}
    }

    const recognition = new SpeechRecognitionAPI()
    recognition.lang           = language === 'de' ? 'de-DE' : 'en-US'
    recognition.interimResults = true   // Show partial results live
    recognition.continuous     = false  // Stop after one utterance
    recognition.maxAlternatives = 1

    recognition.onstart = () => {
      setListening(true)
      setTranscript('Listening...')
    }

    recognition.onresult = (event) => {
      let interimText = ''
      let finalText   = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        if (result.isFinal) {
          finalText += result[0].transcript
        } else {
          interimText += result[0].transcript
        }
      }

      // Show interim results live in the transcript preview
      if (interimText) setTranscript(interimText)

      // When final result arrives, send to agent
      if (finalText.trim()) {
        setTranscript(finalText)
        setListening(false)
        sendToAgent(finalText.trim())
      }
    }

    recognition.onend = () => {
      setListening(false)
    }

    recognition.onerror = (event) => {
      setListening(false)
      if (event.error === 'no-speech') {
        setTranscript('')
        return
      }
      if (event.error === 'not-allowed') {
        setError('Microphone permission denied. Please allow microphone access.')
        return
      }
      console.warn('STT error:', event.error)
    }

    recognitionRef.current = recognition
    try {
      recognition.start()
    } catch (err) {
      console.warn('Could not start recognition:', err)
    }
  }, [language, sendToAgent])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Connect to LiveKit room
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const connect = useCallback(async () => {
    if (!isSpeechRecognitionSupported()) {
      setError('Your browser does not support Speech Recognition. Please use Chrome or Edge.')
      return
    }

    setConnectionStatus('connecting')
    setError('')

    try {
      // 1. Get token from FastAPI backend
      const res = await fetch(
        `${BACKEND_URL}/livekit/token?room=room-1&username=patient-${Date.now()}`
      )
      if (!res.ok) throw new Error(`Token fetch failed: ${res.status}`)
      const { token, url } = await res.json()

      // 2. Create LiveKit room
      const room = new Room({
        adaptiveStream: false,
        dynacast:       false,
      })
      roomRef.current = room

      // 3. Listen for DataChannel messages from agent
      room.on(RoomEvent.DataReceived, (payload, participant) => {
        try {
          const msg = JSON.parse(new TextDecoder().decode(payload))
          console.log('â† Received from agent:', msg)

          if (msg.type === 'agent_response') {
            // Update booking step indicator
            if (msg.state) setAgentState(msg.state)

            // Add to chat log
            addMessage('agent', msg.text)

            // Speak the response
            speak(msg.text)
          }
        } catch (e) {
          console.warn('Could not parse agent message:', e)
        }
      })

      // 4. Handle disconnection
      room.on(RoomEvent.Disconnected, () => {
        setConnectionStatus('offline')
        setListening(false)
        setIsAgentSpeaking(false)
        synthRef.current.cancel()
        roomRef.current = null
      })

      // 5. Connect to LiveKit server
      await room.connect(url, token)
      setConnectionStatus('online')
      console.log('âœ… Connected to LiveKit room')

      // 6. Give voices time to load, then start listening
      // The agent sends a welcome message on connect â€” wait for it
      setTimeout(() => {
        if (synthRef.current.getVoices().length === 0) {
          synthRef.current.onvoiceschanged = () => {
            console.log('Voices loaded:', synthRef.current.getVoices().length)
          }
        }
      }, 500)

    } catch (err) {
      console.error('Connection error:', err)
      setError(`Could not connect: ${err.message}`)
      setConnectionStatus('offline')
      roomRef.current = null
    }
  }, [addMessage, speak])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Disconnect from LiveKit room
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const disconnect = useCallback(async () => {
    synthRef.current.cancel()
    if (recognitionRef.current) {
      try { recognitionRef.current.abort() } catch (_) {}
    }
    if (roomRef.current) {
      await roomRef.current.disconnect()
      roomRef.current = null
    }
    setConnectionStatus('offline')
    setListening(false)
    setIsAgentSpeaking(false)
    setTranscript('')
    setAgentState('idle')
  }, [])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Manual mic button click (when auto-start doesn't trigger)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const handleMicClick = useCallback(() => {
    if (listening) {
      recognitionRef.current?.stop()
      setListening(false)
    } else if (!isAgentSpeaking) {
      startListening()
    }
  }, [listening, isAgentSpeaking, startListening])

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Derive current booking step from agent state
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const currentStep = STATE_TO_STEP[agentState] ?? -1

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Status badge content
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const statusLabels = {
    offline:    'Disconnected',
    connecting: 'Connecting...',
    online:     'Connected',
  }

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Mic button content
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const micButtonState = isAgentSpeaking ? 'speaking'
                       : listening       ? 'listening'
                       : 'idle'

  const micButtonIcon  = isAgentSpeaking ? 'ğŸ”Š'
                       : listening       ? 'ğŸ™ï¸'
                       : 'ğŸ¤'

  const micStatusText  = isAgentSpeaking ? 'Agent is speaking...'
                       : listening       ? 'Listening â€” speak now'
                       : connectionStatus === 'online'
                         ? 'Tap mic to speak'
                         : 'Not connected'

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // Render
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  return (
    <div className="app-wrapper">

      {/* â”€â”€ Header â”€â”€ */}
      <header className="header">
        <div className="header-left">
          <span className="header-logo">ğŸ¥</span>
          <div className="header-title">
            <h1>Functiomed</h1>
            <p>Voice Appointment Assistant</p>
          </div>
        </div>
        <div className={`status-badge ${connectionStatus}`}>
          <span className={`status-dot ${connectionStatus === 'connecting' ? 'pulse' : ''}`} />
          {statusLabels[connectionStatus]}
        </div>
      </header>

      {/* â”€â”€ Browser compatibility warning â”€â”€ */}
      {!isSpeechRecognitionSupported() && (
        <div className="browser-warning">
          âš ï¸ Speech Recognition requires Chrome or Edge. Other browsers are not supported.
        </div>
      )}

      {/* â”€â”€ Error banner â”€â”€ */}
      {error && (
        <div className="error-banner">
          âŒ {error}
        </div>
      )}

      {/* â”€â”€ Booking Progress Stepper â”€â”€ */}
      {connectionStatus === 'online' && currentStep >= 0 && (
        <div className="stepper-card">
          <h3>Booking Progress</h3>
          <div className="stepper">
            {STEPS.map((step, idx) => {
              const stepClass = idx < currentStep  ? 'done'
                              : idx === currentStep ? 'active'
                              : 'upcoming'
              return (
                <div key={step.label} className={`step ${stepClass}`}>
                  <div className="step-circle">
                    {idx < currentStep ? 'âœ“' : step.icon}
                  </div>
                  <span className="step-label">{step.label}</span>
                </div>
              )
            })}
          </div>
        </div>
      )}

      {/* â”€â”€ Chat Messages â”€â”€ */}
      <div className="messages-card">
        {messages.length === 0 ? (
          <div className="empty-chat">
            <div className="empty-icon">ğŸ’¬</div>
            <p>
              {connectionStatus === 'online'
                ? 'Waiting for the agent to greet you...'
                : 'Start a call to talk to the assistant.'}
            </p>
          </div>
        ) : (
          messages.map(msg => (
            <div key={msg.id} className={`message ${msg.role}`}>
              <div className="message-avatar">
                {msg.role === 'agent' ? 'ğŸ¤–' : 'ğŸ‘¤'}
              </div>
              <div className="message-bubble">
                {msg.text}
              </div>
            </div>
          ))
        )}
        <div ref={messagesEndRef} />
      </div>

      {/* â”€â”€ Live transcript preview â”€â”€ */}
      {connectionStatus === 'online' && (
        <div className="transcript-preview">
          <span className="mic-icon">{listening ? 'ğŸ™ï¸' : 'ğŸ’¬'}</span>
          <span>
            {transcript || (isAgentSpeaking ? 'Agent is responding...' : 'Tap the mic button to speak')}
          </span>
        </div>
      )}

      {/* â”€â”€ Controls â”€â”€ */}
      <div className="controls-card">
        {connectionStatus !== 'online' ? (
          /* â”€â”€ Connect button â”€â”€ */
          <div className="btn-row">
            <button
              className="btn-connect"
              onClick={connect}
              disabled={connectionStatus === 'connecting'}
            >
              {connectionStatus === 'connecting' ? 'â³ Connecting...' : 'ğŸ“ Start Call'}
            </button>
          </div>
        ) : (
          /* â”€â”€ Online controls â”€â”€ */
          <>
            {/* Big microphone button */}
            <button
              className={`btn-mic-main ${micButtonState}`}
              onClick={handleMicClick}
              disabled={isAgentSpeaking}
              title={micStatusText}
            >
              {micButtonIcon}
            </button>

            <p className={`mic-status-text ${micButtonState}`}>
              {micStatusText}
            </p>

            {/* Disconnect button */}
            <div className="btn-row">
              <button className="btn-disconnect" onClick={disconnect}>
                ğŸ“µ End Call
              </button>
            </div>
          </>
        )}
      </div>

    </div>
  )
}